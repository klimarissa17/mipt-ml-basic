{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Lab2_DL_part3_poetry.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BF85vFRxtz"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrXVdDtBRxt6"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN7x27G5Rxt7"
      },
      "source": [
        "import string\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr4rnQ6tRxt8"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buBDL2NyRxt8"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CcflgmayRxt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558f4beb-f3dc-4027-d806-e241fd3d8052"
      },
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-13 22:49:03--  https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119748 (117K) [text/plain]\n",
            "Saving to: ‘sonnets.txt’\n",
            "\n",
            "\rsonnets.txt           0%[                    ]       0  --.-KB/s               \rsonnets.txt         100%[===================>] 116.94K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-06-13 22:49:03 (39.7 MB/s) - ‘sonnets.txt’ saved [119748/119748]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uEPH-QNRxt9"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot_4oBoURxt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5a2c0b-066d-4a04-93ea-512e65b47b37"
      },
      "source": [
        "text = ''.join(text).lower()\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WuogzsfRxt_"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeQyBrpsRxuA"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo1a087dRxuA"
      },
      "source": [
        "tokens = sorted(set(text))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bL_angmRxuA"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EY8F-vSARxuB"
      },
      "source": [
        "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
        "idx_to_token = {idx: token for idx, token in enumerate(tokens)}\n",
        "assert len(token_to_idx) == len(idx_to_token)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVY2Eg-PRxuB"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oFnai8TRxuB"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHXjds6pRxuC"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIgS6PqbHYds"
      },
      "source": [
        "def to_matrix(pieces, max_len=None):\n",
        "  if max_len == None: \n",
        "    max_len = max(map(len, pieces))\n",
        "\n",
        "  text_ix = np.zeros((len(pieces), max_len), dtype='int32')\n",
        "  for i in range(len(pieces)): \n",
        "    line_ix = [token_to_idx[c] for c in pieces[i]]\n",
        "    text_ix[i, :len(line_ix)] = line_ix\n",
        "  return text_ix"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkegAyVMUJg7"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = 'cuda'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5NGdMn3UMyY"
      },
      "source": [
        "\n",
        "class CharRNNCell(nn.Module):\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        x_emb = self.embedding(x)\n",
        "        \n",
        "        # compute next hidden state using self.rnn_update\n",
        "        # hint: use torch.cat(..., dim=...) for concatenation\n",
        "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
        "        h_next = self.rnn_update(x_and_h)\n",
        "        h_next = torch.tanh(h_next)\n",
        "        assert h_next.size() == h_prev.size()\n",
        "        \n",
        "        #compute logits for next character probs\n",
        "        logits = self.rnn_to_logits(h_next)\n",
        "        return h_next, F.log_softmax(logits, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units, requires_grad=True).to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVTRQ5hSRpHs"
      },
      "source": [
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in names_ix\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "    logprobs = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0,1):\n",
        "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
        "        logprobs.append(logp_next)\n",
        "        \n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnIyzrzGvMqi"
      },
      "source": [
        "def get_shifts(num, start=0, piece_len=100, step=1):\n",
        "  res = []\n",
        "  for i in range(num): \n",
        "    if start + piece_len >= len(text) - 1:\n",
        "      print(\"ooops\")\n",
        "      break\n",
        "    res.append(text[start:start+piece_len])\n",
        "    start += step\n",
        "  return res"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv8la_TMB5dV"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from random import sample\n",
        "from tqdm import trange\n",
        "\n",
        "char_rnn = CharRNNCell().to(device)\n",
        "opt = torch.optim.Adam(char_rnn.parameters())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjBbZ1OrHM-l"
      },
      "source": [
        "def training_loop(rnn, opt, epochs=30):\n",
        "  loss_history = []\n",
        "  for epoch in range(epochs):\n",
        "    loss_this_epoch = 0\n",
        "    for batch_idx in trange(NUM_BATCHES):\n",
        "      pieces = get_shifts(BATCH_SIZE, start=batch_idx * BATCH_SIZE, piece_len=MAX_LEN)\n",
        "      samples = torch.tensor(to_matrix(pieces), dtype=torch.int64).to(device)\n",
        "      batch_ix = samples[:, :-1]\n",
        "      opt.zero_grad()\n",
        "      logp_seq = rnn_loop(rnn, batch_ix)\n",
        "      actual_next_tokens = samples[:, 1:]\n",
        "      predictions_logp = logp_seq\n",
        "      logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "      loss = -logp_next.mean()\n",
        "      #loss_history.append(loss.detach().cpu().numpy())\n",
        "      loss_this_epoch += loss.detach().cpu().numpy()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "    loss_this_epoch /= NUM_BATCHES\n",
        "    print('Training epoch: {} Loss: {}'.format(epoch, loss_this_epoch))\n",
        "    loss_history.append(loss_this_epoch)\n",
        "    clear_output(True)\n",
        "    plt.plot(loss_history,label='loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  return loss_history"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRQ7xm4KIQwe"
      },
      "source": [
        "MAX_LEN = 120\n",
        "BATCH_SIZE = 200\n",
        "NUM_BATCHES = (len(text) - MAX_LEN) // BATCH_SIZE"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4j3Z-DTUmuq"
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm._instances.clear()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swtQUBofIUcJ",
        "outputId": "f1baa0b5-b978-42a8-a735-a52cb18e8ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "loss_history = training_loop(char_rnn, opt, 35)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SEZK4R9RxuD"
      },
      "source": [
        "MAX_LEN = 100\n",
        "def generate_sample(char_rnn, seed_phrase='hello', max_length=MAX_LEN, temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs, \n",
        "        smaller temperature converges to the single most likely output.\n",
        "        \n",
        "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
        "    of the next symbol.\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "  \n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        # print(x_sequence[:, -1].shape, hid_state.shape)\n",
        "        hid_state, out = char_rnn(x_sequence[:, i], hid_state)\n",
        "  \n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, out = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        # Be really careful here with the model output\n",
        "        p_next = F.softmax(out / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.cpu().numpy()[0]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VxrSLBIypcd",
        "outputId": "8eac236b-98f5-477b-87cc-72e316548c11"
      },
      "source": [
        "# An example of generated text.\n",
        "print(generate_sample(char_rnn, seed_phrase='love', max_length=500, temperature=0.8))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "love?\n",
            "  for thered thy goods the from thy fair bat which all thy glory all the blow;\n",
            "  my foust i clo'd better be condast that in thy eyes as thee, see chand art a the better fall the love;\n",
            "  thee,\n",
            "  and suspeds be i all thou dost the trunkine!\n",
            "  in my bater's proud how my praaty is thy greated,\n",
            "    hour die,\n",
            "  and may, i  thine,\n",
            "  who doth lovery wilt creater's for on thy love is deswith hyous forgets have belings hath paron not heers wite!\n",
            "  on thee, to to have five heart, who all they slave f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux2O8g2BRxuE"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgsuFT0ZRxuE"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfhphNOzrYPM"
      },
      "source": [
        "device = 'cuda'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sOYIo1LpRxuF"
      },
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.LSTMCell(embedding_size, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        x_emb = self.embedding(x)\n",
        "        \n",
        "        # compute next hidden state using self.rnn_update\n",
        "        # hint: use torch.cat(..., dim=...) for concatenation\n",
        "        h_next = self.rnn_update(x_emb, h_prev)\n",
        "        \n",
        "        #compute logits for next character probs\n",
        "        logits = self.rnn_to_logits(h_next[0])\n",
        "        return h_next, F.log_softmax(logits, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return [torch.zeros(batch_size, self.num_units, requires_grad=True).to(device) for i in range(2)]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBjPJoETsidn"
      },
      "source": [
        "lstm_rnn = LSTMCell().to(device)\n",
        "lstm_opt = torch.optim.Adam(lstm_rnn.parameters())"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lja1JtmdLwEZ",
        "outputId": "d8925257-a964-4d0d-a6c6-70193f58f28f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "loss_history_lstm = training_loop(lstm_rnn, lstm_opt, 35)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo7cN2RTxZst",
        "outputId": "aad3a895-f7d6-4eb6-df3c-8a9a542a26d0"
      },
      "source": [
        "print(generate_sample(lstm_rnn, seed_phrase='love', max_length=500, temperature=1))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "love she tencack\n",
            "  the suration it, when do me their ginst make agatt is is ronebuless,\n",
            "  fith your polowing just on my as false sways,-sman to is all:\n",
            "    and foul fairs did forget to tweep, this to bespoin's end\n",
            "  whereight swarly fool mor'trow thee, me,\n",
            "  since should now which is holcods thee mose,--:\n",
            "  my vandest to i and hollel your hipps alavel\n",
            "  a joy took same as hor, be thy showing mack,\n",
            "  not the love reath make my love not so that eye;\n",
            "  for this see hath withanty shorken by deteraca\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB5N4XySRxuF"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TvhmEY6nRxuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77940854-0f77-4072-a923-7365c6a59423"
      },
      "source": [
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='love', max_length=500, temperature=0.1))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='love', max_length=500, temperature=0.2))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='love', max_length=500, temperature=0.5))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='love', max_length=500, temperature=1))\n",
        "print(\"\\n***\\n\")\n",
        "print(generate_sample(lstm_rnn, seed_phrase='love', max_length=500, temperature=2))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "***\n",
            "\n",
            "love thee the strange thee thee thee the strange thee thee thee to thee,\n",
            "  the world thee the world thee thee the confound thee thee,\n",
            "    then the world that the world thee the sunself the world thee i am my self thee the strange thee thee i do my self thee thee to thee thee thee,\n",
            "    and the world the world thee the world that thee the from thee thee to thee.\n",
            "\n",
            "  cxlvii\n",
            "\n",
            "  that the world that the world the world that thee thee in thee,\n",
            "    then the worth the world thee the suns to thee the compo\n",
            "\n",
            "***\n",
            "\n",
            "love thee thee and the world thee the dear thee for thee to thee prove.\n",
            "    then the suns thou shall i am not the spends with thee the proud thee of my seed\n",
            "  the proud thou thee the belove thee to thee the bears thee proud the from heart,\n",
            "    then i and the world thou thee the worth my self and thee to thee,\n",
            "    that i and i sweet thou thee for thee thee me the strange thee the state.\n",
            "  the contenties thee i do my sour'd to thee to be the confounds,\n",
            "  and the worth i am the mayst thee for thee \n",
            "\n",
            "***\n",
            "\n",
            "love make in the strange are for thee comphate:\n",
            "    then the better thy more my sorrouth the seen'd and the greas,\n",
            "  my happay hate my beauty before,\n",
            "  which have that they badough thy praise of my spent thou doth griend.\n",
            "\n",
            "  cxlii\n",
            "\n",
            "  i not from heaven that part thy wearth compure or swornough with woes,\n",
            "  that thee the proud the say thy love to dead,\n",
            "  all things of the growns thou make me art be art,\n",
            "  the be a that i have he be to me, the belies my prove:\n",
            "    then me be the shound the true far\n",
            "\n",
            "***\n",
            "\n",
            "love inden's\n",
            "  in thee houchse that my nor mend;\n",
            "  so new! two my proked upbing, is and that in,\n",
            "  the uruse with hath up thou prown, alls dote me not,\n",
            "    not by that of this rade i long life,\n",
            "  which their bettione what fals can loves of thee won excuse,\n",
            "    ow love for by love un i inginds from hathe.\n",
            "  when never a main, that to storns to to the grace.\n",
            "  which plowast, my life and the rust-lose\n",
            "  what with will is strowni'l knows,\n",
            "  wheres freshers' despends i she kind noth com me stan.\n",
            "    \n",
            "\n",
            "***\n",
            "\n",
            "loves lamc'l,-not crong;\n",
            " n flair dembyl-istemusaband!r nore.'\n",
            "  vils; uir greet rnaw;-kill find\n",
            "  can\n",
            "; im dut o'a' spor nngienals motut;\n",
            "  staid larsesn thengrio'' dagk,\n",
            "  so!lbint, o! uprof frow' witirts crejuely;\n",
            "   inlisha hip-swriil, i,s thaisnsguan abosn\n",
            "  bedy 'trivet!\n",
            "  crnight-ngeng is urfugixbul'd-rhalr, andoigh,mins cadilcpentical,\n",
            "  ureby dewe\n",
            "  telf madmfivy', tgotooy-)orr? the sgandhhnfing, ortaavienctp'chanys-stwat;\n",
            "- loskint dening'd, am to agach-lracle'd,\n",
            "  cake ancu: 'fiam i j\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_coTrTet6bl"
      },
      "source": [
        "We can see that on low temperature (like 0.1) the net often repeats the same words (probably the most frequent) so the generated text mostly consists of \"thee\" and \"the world\". Not much fun, actually. \n",
        "\n",
        "On 0.2 the situation is pretty similar, but there are more different words appearing, lines are usually shorter (that's good). \n",
        "\n",
        "0.5 is nice, no weird repetitions and most of the words are real. It still does not make any sense, but that's not what we're here for.\n",
        "\n",
        "1.0 is my fav here! Beautiful structure, lots of punctuation, some grammatically correct pieces can be found.\n",
        "\n",
        "On 2.0 the net goes crazy and just messes everything up. No meaningful or at least readable words, punctuation everywhere."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPL14oaVRxuG"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh544JDnRxuH"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ha3Gzh5ERxuH"
      },
      "source": [
        "torch.save(lstm_rnn, 'model')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l_imalBx-iH"
      },
      "source": [
        "loaded = torch.load('model')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK-RhmzVyD1-",
        "outputId": "917b1041-f095-4119-b8ce-88a4c426a8a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(generate_sample(loaded, seed_phrase='love', max_length=500, temperature=0.8))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "love in a so,\n",
            "    and him i not the alone with to this most love and bland?\n",
            "  he me, and take is thans is fair for-timmer sane eye which is will hand self!\n",
            "  the being for musen my be uncelf power a from thee am bring.\n",
            "  for thou not to thy which i he othit i chadon's.\n",
            "  my preftords to thy rose; that puring end:\n",
            "    for that turn this i do uplook hand to art,\n",
            "  each truth that were thy floveress'd there so thou grate\n",
            "  my change i wold that with your peatter'd a deserous,\n",
            "  then wastrel hath th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFoG23j4RxuH"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}