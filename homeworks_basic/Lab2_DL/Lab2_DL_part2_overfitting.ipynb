{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Overfit it.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFmOh482SyEF"
      },
      "source": [
        "## Lab 2\n",
        "### Part 2: Dealing with overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjzAuO3oSvsI"
      },
      "source": [
        "Today we work with [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) (*hint: it is available in `torchvision`*).\n",
        "\n",
        "Your goal for today:\n",
        "1. Train a FC (fully-connected) network that achieves >= 0.885 test accuracy.\n",
        "2. Cause considerable overfitting by modifying the network (e.g. increasing the number of network parameters and/or layers) and demonstrate in in the appropriate way (e.g. plot loss and accurasy on train and validation set w.r.t. network complexity).\n",
        "3. Try to deal with overfitting (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results.\n",
        "\n",
        "__Please, write a small report describing your ideas, tries and achieved results in the end of this file.__\n",
        "\n",
        "*Note*: Tasks 2 and 3 are interrelated, in task 3 your goal is to make the network from task 2 less prone to overfitting. Task 1 is independent from 2 and 3.\n",
        "\n",
        "*Note 2*: We recomment to use Google Colab or other machine with GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KBld6VOSwhW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchsummary\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdLOG0XqS_g5",
        "outputId": "fd25393b-23b2-42b3-f636-8ece5a023964"
      },
      "source": [
        "# Technical function\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(root_path):\n",
        "        os.mkdir(root_path)\n",
        "        print('Directory', path, 'is created!')\n",
        "    else:\n",
        "        print('Directory', path, 'already exists!')\n",
        "        \n",
        "root_path = 'fmnist'\n",
        "mkdir(root_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory fmnist already exists!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt6LE7XaTDT9"
      },
      "source": [
        "download = True\n",
        "train_transform = transforms.ToTensor()\n",
        "test_transform = transforms.ToTensor()\n",
        "transforms.Compose((transforms.ToTensor()))\n",
        "\n",
        "\n",
        "fmnist_dataset_train = torchvision.datasets.FashionMNIST(root_path, \n",
        "                                                        train=True, \n",
        "                                                        transform=train_transform,\n",
        "                                                        target_transform=None,\n",
        "                                                        download=download)\n",
        "fmnist_dataset_test = torchvision.datasets.FashionMNIST(root_path, \n",
        "                                                       train=False, \n",
        "                                                       transform=test_transform,\n",
        "                                                       target_transform=None,\n",
        "                                                       download=download)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71YP0SPwTIxD"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(fmnist_dataset_train, \n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(fmnist_dataset_test,\n",
        "                                          batch_size=256,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_YFmF7NTWrQ",
        "outputId": "dac82283-20af-4795-9f22-bdce97906458"
      },
      "source": [
        "len(fmnist_dataset_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHca15bOTY4B",
        "outputId": "2c9d39f9-f2ae-499b-c763-e9598f78f282"
      },
      "source": [
        "for img, label in train_loader:\n",
        "    print(img.shape)\n",
        "#     print(img)\n",
        "    print(label.shape)\n",
        "    print(label.size(0))\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128])\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6OOOffHTfX5"
      },
      "source": [
        "### Task 1\n",
        "Train a network that achieves $\\geq 0.885$ test accuracy. It's fine to use only Linear (`nn.Linear`) layers and activations/dropout/batchnorm. Convolutional layers might be a great use, but we will meet them a bit later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftpkTjxlTcFx"
      },
      "source": [
        "class TinyNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        some_const = 600\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
        "            # Your network structure comes here\n",
        "            nn.Linear(input_shape, some_const),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(some_const, some_const),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(some_const, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        return self.model(inp)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WmJp44uMvSh",
        "outputId": "73e2023d-3a1b-4941-c704-a4dbbeb24531"
      },
      "source": [
        "torchsummary.summary(TinyNeuralNetwork().to(device), (28*28,))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                  [-1, 600]         471,000\n",
            "         LeakyReLU-3                  [-1, 600]               0\n",
            "            Linear-4                  [-1, 600]         360,600\n",
            "         LeakyReLU-5                  [-1, 600]               0\n",
            "            Linear-6                   [-1, 10]           6,010\n",
            "================================================================\n",
            "Total params: 837,610\n",
            "Trainable params: 837,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 3.20\n",
            "Estimated Total Size (MB): 3.22\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "544PGKEnjPr5"
      },
      "source": [
        "Your experiments come here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3POFj90Ti-6",
        "outputId": "ec9e590f-81c1-412b-ff09-e9bfd782cb28"
      },
      "source": [
        "model = TinyNeuralNetwork().to(device)\n",
        "learning_rate = 1e-2\n",
        "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# Your experiments, training and validation loops here\n",
        "epochs = 30\n",
        "log_interval=100\n",
        "training_accuracy = 0\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    opt.zero_grad()\n",
        "    model_out = model(data)\n",
        "    model_out = model_out.to(device)\n",
        "    training_accuracy += (torch.eq(target, torch.argmax(model_out, -1)).float().mean())\n",
        "    loss = loss_func(model_out, target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loss_history.append(loss)\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]tLoss: {:.6f}'.format(\n",
        "                   epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                          100. * batch_idx / len(train_loader), loss.data))\n",
        "  training_accuracy = training_accuracy / batch_idx\n",
        "  print('Training accuracy: ' + str(float(training_accuracy)))\n",
        "  training_accuracy = 0"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]tLoss: 2.304928\n",
            "Train Epoch: 0 [12800/60000 (21%)]tLoss: 0.829628\n",
            "Train Epoch: 0 [25600/60000 (43%)]tLoss: 0.760935\n",
            "Train Epoch: 0 [38400/60000 (64%)]tLoss: 0.613395\n",
            "Train Epoch: 0 [51200/60000 (85%)]tLoss: 0.459715\n",
            "Training accuracy: 0.7105202078819275\n",
            "Train Epoch: 1 [0/60000 (0%)]tLoss: 0.488095\n",
            "Train Epoch: 1 [12800/60000 (21%)]tLoss: 0.448559\n",
            "Train Epoch: 1 [25600/60000 (43%)]tLoss: 0.532792\n",
            "Train Epoch: 1 [38400/60000 (64%)]tLoss: 0.407067\n",
            "Train Epoch: 1 [51200/60000 (85%)]tLoss: 0.442647\n",
            "Training accuracy: 0.8303285837173462\n",
            "Train Epoch: 2 [0/60000 (0%)]tLoss: 0.364808\n",
            "Train Epoch: 2 [12800/60000 (21%)]tLoss: 0.409744\n",
            "Train Epoch: 2 [25600/60000 (43%)]tLoss: 0.552709\n",
            "Train Epoch: 2 [38400/60000 (64%)]tLoss: 0.406365\n",
            "Train Epoch: 2 [51200/60000 (85%)]tLoss: 0.374583\n",
            "Training accuracy: 0.8505163788795471\n",
            "Train Epoch: 3 [0/60000 (0%)]tLoss: 0.309542\n",
            "Train Epoch: 3 [12800/60000 (21%)]tLoss: 0.371626\n",
            "Train Epoch: 3 [25600/60000 (43%)]tLoss: 0.465768\n",
            "Train Epoch: 3 [38400/60000 (64%)]tLoss: 0.439649\n",
            "Train Epoch: 3 [51200/60000 (85%)]tLoss: 0.436626\n",
            "Training accuracy: 0.8605157136917114\n",
            "Train Epoch: 4 [0/60000 (0%)]tLoss: 0.283486\n",
            "Train Epoch: 4 [12800/60000 (21%)]tLoss: 0.425061\n",
            "Train Epoch: 4 [25600/60000 (43%)]tLoss: 0.262443\n",
            "Train Epoch: 4 [38400/60000 (64%)]tLoss: 0.303639\n",
            "Train Epoch: 4 [51200/60000 (85%)]tLoss: 0.476399\n",
            "Training accuracy: 0.8696414828300476\n",
            "Train Epoch: 5 [0/60000 (0%)]tLoss: 0.519686\n",
            "Train Epoch: 5 [12800/60000 (21%)]tLoss: 0.424139\n",
            "Train Epoch: 5 [25600/60000 (43%)]tLoss: 0.395666\n",
            "Train Epoch: 5 [38400/60000 (64%)]tLoss: 0.305197\n",
            "Train Epoch: 5 [51200/60000 (85%)]tLoss: 0.461759\n",
            "Training accuracy: 0.8748887181282043\n",
            "Train Epoch: 6 [0/60000 (0%)]tLoss: 0.189315\n",
            "Train Epoch: 6 [12800/60000 (21%)]tLoss: 0.369811\n",
            "Train Epoch: 6 [25600/60000 (43%)]tLoss: 0.300281\n",
            "Train Epoch: 6 [38400/60000 (64%)]tLoss: 0.306828\n",
            "Train Epoch: 6 [51200/60000 (85%)]tLoss: 0.242999\n",
            "Training accuracy: 0.8811988234519958\n",
            "Train Epoch: 7 [0/60000 (0%)]tLoss: 0.418205\n",
            "Train Epoch: 7 [12800/60000 (21%)]tLoss: 0.307130\n",
            "Train Epoch: 7 [25600/60000 (43%)]tLoss: 0.276536\n",
            "Train Epoch: 7 [38400/60000 (64%)]tLoss: 0.332279\n",
            "Train Epoch: 7 [51200/60000 (85%)]tLoss: 0.306122\n",
            "Training accuracy: 0.8846877217292786\n",
            "Train Epoch: 8 [0/60000 (0%)]tLoss: 0.262301\n",
            "Train Epoch: 8 [12800/60000 (21%)]tLoss: 0.322488\n",
            "Train Epoch: 8 [25600/60000 (43%)]tLoss: 0.369398\n",
            "Train Epoch: 8 [38400/60000 (64%)]tLoss: 0.291099\n",
            "Train Epoch: 8 [51200/60000 (85%)]tLoss: 0.277010\n",
            "Training accuracy: 0.8875534534454346\n",
            "Train Epoch: 9 [0/60000 (0%)]tLoss: 0.427894\n",
            "Train Epoch: 9 [12800/60000 (21%)]tLoss: 0.252940\n",
            "Train Epoch: 9 [25600/60000 (43%)]tLoss: 0.316415\n",
            "Train Epoch: 9 [38400/60000 (64%)]tLoss: 0.329471\n",
            "Train Epoch: 9 [51200/60000 (85%)]tLoss: 0.229912\n",
            "Training accuracy: 0.8925169110298157\n",
            "Train Epoch: 10 [0/60000 (0%)]tLoss: 0.218737\n",
            "Train Epoch: 10 [12800/60000 (21%)]tLoss: 0.290582\n",
            "Train Epoch: 10 [25600/60000 (43%)]tLoss: 0.263616\n",
            "Train Epoch: 10 [38400/60000 (64%)]tLoss: 0.196623\n",
            "Train Epoch: 10 [51200/60000 (85%)]tLoss: 0.242028\n",
            "Training accuracy: 0.8958834409713745\n",
            "Train Epoch: 11 [0/60000 (0%)]tLoss: 0.170621\n",
            "Train Epoch: 11 [12800/60000 (21%)]tLoss: 0.242563\n",
            "Train Epoch: 11 [25600/60000 (43%)]tLoss: 0.519086\n",
            "Train Epoch: 11 [38400/60000 (64%)]tLoss: 0.210465\n",
            "Train Epoch: 11 [51200/60000 (85%)]tLoss: 0.398017\n",
            "Training accuracy: 0.898298442363739\n",
            "Train Epoch: 12 [0/60000 (0%)]tLoss: 0.424597\n",
            "Train Epoch: 12 [12800/60000 (21%)]tLoss: 0.444841\n",
            "Train Epoch: 12 [25600/60000 (43%)]tLoss: 0.246854\n",
            "Train Epoch: 12 [38400/60000 (64%)]tLoss: 0.324942\n",
            "Train Epoch: 12 [51200/60000 (85%)]tLoss: 0.434457\n",
            "Training accuracy: 0.9002737998962402\n",
            "Train Epoch: 13 [0/60000 (0%)]tLoss: 0.255729\n",
            "Train Epoch: 13 [12800/60000 (21%)]tLoss: 0.220103\n",
            "Train Epoch: 13 [25600/60000 (43%)]tLoss: 0.287208\n",
            "Train Epoch: 13 [38400/60000 (64%)]tLoss: 0.353299\n",
            "Train Epoch: 13 [51200/60000 (85%)]tLoss: 0.242660\n",
            "Training accuracy: 0.9030671715736389\n",
            "Train Epoch: 14 [0/60000 (0%)]tLoss: 0.297962\n",
            "Train Epoch: 14 [12800/60000 (21%)]tLoss: 0.208051\n",
            "Train Epoch: 14 [25600/60000 (43%)]tLoss: 0.267200\n",
            "Train Epoch: 14 [38400/60000 (64%)]tLoss: 0.149895\n",
            "Train Epoch: 14 [51200/60000 (85%)]tLoss: 0.290487\n",
            "Training accuracy: 0.9064058065414429\n",
            "Train Epoch: 15 [0/60000 (0%)]tLoss: 0.232425\n",
            "Train Epoch: 15 [12800/60000 (21%)]tLoss: 0.327125\n",
            "Train Epoch: 15 [25600/60000 (43%)]tLoss: 0.297324\n",
            "Train Epoch: 15 [38400/60000 (64%)]tLoss: 0.226058\n",
            "Train Epoch: 15 [51200/60000 (85%)]tLoss: 0.351254\n",
            "Training accuracy: 0.9071292281150818\n",
            "Train Epoch: 16 [0/60000 (0%)]tLoss: 0.263469\n",
            "Train Epoch: 16 [12800/60000 (21%)]tLoss: 0.209594\n",
            "Train Epoch: 16 [25600/60000 (43%)]tLoss: 0.147390\n",
            "Train Epoch: 16 [38400/60000 (64%)]tLoss: 0.149868\n",
            "Train Epoch: 16 [51200/60000 (85%)]tLoss: 0.138962\n",
            "Training accuracy: 0.910373330116272\n",
            "Train Epoch: 17 [0/60000 (0%)]tLoss: 0.200335\n",
            "Train Epoch: 17 [12800/60000 (21%)]tLoss: 0.230884\n",
            "Train Epoch: 17 [25600/60000 (43%)]tLoss: 0.217678\n",
            "Train Epoch: 17 [38400/60000 (64%)]tLoss: 0.201794\n",
            "Train Epoch: 17 [51200/60000 (85%)]tLoss: 0.167763\n",
            "Training accuracy: 0.9130498170852661\n",
            "Train Epoch: 18 [0/60000 (0%)]tLoss: 0.303713\n",
            "Train Epoch: 18 [12800/60000 (21%)]tLoss: 0.265083\n",
            "Train Epoch: 18 [25600/60000 (43%)]tLoss: 0.204555\n",
            "Train Epoch: 18 [38400/60000 (64%)]tLoss: 0.267287\n",
            "Train Epoch: 18 [51200/60000 (85%)]tLoss: 0.256702\n",
            "Training accuracy: 0.9154536128044128\n",
            "Train Epoch: 19 [0/60000 (0%)]tLoss: 0.194423\n",
            "Train Epoch: 19 [12800/60000 (21%)]tLoss: 0.252366\n",
            "Train Epoch: 19 [25600/60000 (43%)]tLoss: 0.250753\n",
            "Train Epoch: 19 [38400/60000 (64%)]tLoss: 0.263071\n",
            "Train Epoch: 19 [51200/60000 (85%)]tLoss: 0.247347\n",
            "Training accuracy: 0.9174624681472778\n",
            "Train Epoch: 20 [0/60000 (0%)]tLoss: 0.207922\n",
            "Train Epoch: 20 [12800/60000 (21%)]tLoss: 0.241505\n",
            "Train Epoch: 20 [25600/60000 (43%)]tLoss: 0.342518\n",
            "Train Epoch: 20 [38400/60000 (64%)]tLoss: 0.206963\n",
            "Train Epoch: 20 [51200/60000 (85%)]tLoss: 0.220099\n",
            "Training accuracy: 0.9177851676940918\n",
            "Train Epoch: 21 [0/60000 (0%)]tLoss: 0.157058\n",
            "Train Epoch: 21 [12800/60000 (21%)]tLoss: 0.198704\n",
            "Train Epoch: 21 [25600/60000 (43%)]tLoss: 0.157919\n",
            "Train Epoch: 21 [38400/60000 (64%)]tLoss: 0.187671\n",
            "Train Epoch: 21 [51200/60000 (85%)]tLoss: 0.201144\n",
            "Training accuracy: 0.920300304889679\n",
            "Train Epoch: 22 [0/60000 (0%)]tLoss: 0.184828\n",
            "Train Epoch: 22 [12800/60000 (21%)]tLoss: 0.195525\n",
            "Train Epoch: 22 [25600/60000 (43%)]tLoss: 0.189422\n",
            "Train Epoch: 22 [38400/60000 (64%)]tLoss: 0.172361\n",
            "Train Epoch: 22 [51200/60000 (85%)]tLoss: 0.232867\n",
            "Training accuracy: 0.9222367405891418\n",
            "Train Epoch: 23 [0/60000 (0%)]tLoss: 0.257791\n",
            "Train Epoch: 23 [12800/60000 (21%)]tLoss: 0.229083\n",
            "Train Epoch: 23 [25600/60000 (43%)]tLoss: 0.170748\n",
            "Train Epoch: 23 [38400/60000 (64%)]tLoss: 0.283944\n",
            "Train Epoch: 23 [51200/60000 (85%)]tLoss: 0.196822\n",
            "Training accuracy: 0.9232494235038757\n",
            "Train Epoch: 24 [0/60000 (0%)]tLoss: 0.219141\n",
            "Train Epoch: 24 [12800/60000 (21%)]tLoss: 0.274298\n",
            "Train Epoch: 24 [25600/60000 (43%)]tLoss: 0.248856\n",
            "Train Epoch: 24 [38400/60000 (64%)]tLoss: 0.128010\n",
            "Train Epoch: 24 [51200/60000 (85%)]tLoss: 0.246450\n",
            "Training accuracy: 0.9245237708091736\n",
            "Train Epoch: 25 [0/60000 (0%)]tLoss: 0.171172\n",
            "Train Epoch: 25 [12800/60000 (21%)]tLoss: 0.225710\n",
            "Train Epoch: 25 [25600/60000 (43%)]tLoss: 0.240374\n",
            "Train Epoch: 25 [38400/60000 (64%)]tLoss: 0.224294\n",
            "Train Epoch: 25 [51200/60000 (85%)]tLoss: 0.295376\n",
            "Training accuracy: 0.9270778298377991\n",
            "Train Epoch: 26 [0/60000 (0%)]tLoss: 0.225290\n",
            "Train Epoch: 26 [12800/60000 (21%)]tLoss: 0.258475\n",
            "Train Epoch: 26 [25600/60000 (43%)]tLoss: 0.223876\n",
            "Train Epoch: 26 [38400/60000 (64%)]tLoss: 0.137373\n",
            "Train Epoch: 26 [51200/60000 (85%)]tLoss: 0.199974\n",
            "Training accuracy: 0.9288139343261719\n",
            "Train Epoch: 27 [0/60000 (0%)]tLoss: 0.193059\n",
            "Train Epoch: 27 [12800/60000 (21%)]tLoss: 0.169020\n",
            "Train Epoch: 27 [25600/60000 (43%)]tLoss: 0.170789\n",
            "Train Epoch: 27 [38400/60000 (64%)]tLoss: 0.197533\n",
            "Train Epoch: 27 [51200/60000 (85%)]tLoss: 0.256279\n",
            "Training accuracy: 0.9289308190345764\n",
            "Train Epoch: 28 [0/60000 (0%)]tLoss: 0.252039\n",
            "Train Epoch: 28 [12800/60000 (21%)]tLoss: 0.168320\n",
            "Train Epoch: 28 [25600/60000 (43%)]tLoss: 0.177896\n",
            "Train Epoch: 28 [38400/60000 (64%)]tLoss: 0.159999\n",
            "Train Epoch: 28 [51200/60000 (85%)]tLoss: 0.230532\n",
            "Training accuracy: 0.9316239953041077\n",
            "Train Epoch: 29 [0/60000 (0%)]tLoss: 0.157276\n",
            "Train Epoch: 29 [12800/60000 (21%)]tLoss: 0.189419\n",
            "Train Epoch: 29 [25600/60000 (43%)]tLoss: 0.163954\n",
            "Train Epoch: 29 [38400/60000 (64%)]tLoss: 0.158031\n",
            "Train Epoch: 29 [51200/60000 (85%)]tLoss: 0.185759\n",
            "Training accuracy: 0.9318910837173462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "Ud7kDqi8ySix",
        "outputId": "6fe5ce68-3e98-427e-f7dd-5c8329b7980c"
      },
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "test_accuracy = 0\n",
        "loss_history = []\n",
        "\n",
        "for data, target in test_loader:\n",
        "   data = data.to(device)\n",
        "   target = target.to(device)\n",
        "   model_out = model(data)\n",
        "   loss = loss_func(model_out, target).data\n",
        "   test_loss += loss\n",
        "   #loss_history.append(loss)\n",
        "   test_accuracy += torch.eq(target, torch.argmax(model_out.data, -1)).float().mean()\n",
        "\n",
        "\n",
        "test_loss = torch.tensor(loss_history).sum() / len(test_loader.dataset)\n",
        "test_accuracy /= len(test_loader)\n",
        "print('Average loss: {:.4f}, Accuracy: {:.4f}'.format(\n",
        "       test_loss, test_accuracy, len(test_loader.dataset)))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "    \n",
        "plt.title(\"Test loss\")\n",
        "plt.xlabel(\"#iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_history, 'b')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %f' % loss)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss: 0.0000, Accuracy: 0.8077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 0.312632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ISqkjmCPB1"
      },
      "source": [
        "### Task 2: Overfit it.\n",
        "Build a network that will overfit to this dataset. Demonstrate the overfitting in the appropriate way (e.g. plot loss and accurasy on train and test set w.r.t. network complexity).\n",
        "\n",
        "*Note:* you also might decrease the size of `train` dataset to enforce the overfitting and speed up the computations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H12uAWiGBwJx"
      },
      "source": [
        "class OverfittingNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        some_big_const = 1800\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
        "            nn.Linear(input_shape, some_big_const), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(some_big_const, input_shape), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(input_shape, input_shape), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(input_shape, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        return self.model(inp)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgXAKCpvCwqH",
        "outputId": "10439e6a-2c25-4548-c99a-07d5eba685de"
      },
      "source": [
        "torchsummary.summary(OverfittingNeuralNetwork().to(device), (28*28,))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                 [-1, 1800]       1,413,000\n",
            "              ReLU-3                 [-1, 1800]               0\n",
            "            Linear-4                  [-1, 784]       1,411,984\n",
            "              ReLU-5                  [-1, 784]               0\n",
            "            Linear-6                  [-1, 784]         615,440\n",
            "              ReLU-7                  [-1, 784]               0\n",
            "            Linear-8                   [-1, 10]           7,850\n",
            "================================================================\n",
            "Total params: 3,448,274\n",
            "Trainable params: 3,448,274\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 13.15\n",
            "Estimated Total Size (MB): 13.21\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "A4tNCr25VMhW",
        "outputId": "a380441b-f65e-4dcb-c44d-31d1a5878422"
      },
      "source": [
        "model =  OverfittingNeuralNetwork().to(device)\n",
        "learning_rate = 1e-2\n",
        "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "print(fmnist_dataset_train.data.shape)\n",
        "train_loader_trunc = torch.utils.data.DataLoader(fmnist_dataset_train[:15000], \n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c5ded2725b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            num_workers=2)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_trunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "DxqxiOlbMvSi",
        "outputId": "4e0b1c03-acf4-403f-d295-d4f95655e95c"
      },
      "source": [
        "model =  OverfittingNeuralNetwork().to(device)\n",
        "learning_rate = 1e-2\n",
        "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "#loss_func = nn.NLLLoss()\n",
        "\n",
        "\n",
        "# Your experiments, training and validation loops here\n",
        "epochs = 40\n",
        "log_interval=100\n",
        "training_batch_size = 128\n",
        "training_accuracy = 0\n",
        "\n",
        "loss_history = []\n",
        "loss_history_test = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader_trunc):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    opt.zero_grad()\n",
        "    model_out = model(data).to(device)\n",
        "    training_accuracy += (torch.eq(target, torch.argmax(model_out, -1)).float().mean())\n",
        "    loss = loss_func(model_out, target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loss_history.append(loss)\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]tLoss: {:.6f}'.format(\n",
        "                   epoch, batch_idx * len(data), len(train_loader_trunc.dataset),\n",
        "                          100. * batch_idx / len(train_loader_trunc), loss.data))\n",
        "  training_accuracy = training_accuracy / batch_idx\n",
        "  print('Training accuracy: ' + str(float(training_accuracy)))\n",
        "  training_accuracy = 0\n",
        "\n",
        "  test_loss = torch.tensor(np.ndarray((256, 10))).to(device)\n",
        "  for test_data, test_target in test_loader:\n",
        "    test_data = test_data.to(device)\n",
        "    test_target = test_target.to(device)\n",
        "    model_out = model(test_data).to(device)\n",
        "    test_loss += loss_func(model_out, test_target)\n",
        "    \n",
        "    \n",
        "  print(test_loss.mean() / len(test_loader))\n",
        "  loss_history_test.append(test_loss.mean() / len(test_loader))\n",
        "  \n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "    \n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"#iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_history_test, 'b')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %f' % loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-00d549502e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Xv_vn6N6Xv-F",
        "outputId": "49925d53-b21e-42ad-8eec-8937dfb72ecd"
      },
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "    \n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"#iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_history_test, 'b')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %f' % loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 0.120789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wPYYhU_gADjg",
        "outputId": "53ea4f12-e624-4f37-c8f7-386a3fac3f17"
      },
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "test_accuracy = 0\n",
        "loss_history = []\n",
        "\n",
        "for data, target in test_loader:\n",
        "   data = data.to(device)\n",
        "   target = target.to(device)\n",
        "   model_out = model(data)\n",
        "   loss = loss_func(model_out, target)\n",
        "   test_loss += loss\n",
        "   loss_history.append(loss)\n",
        "   test_accuracy += torch.eq(target, torch.argmax(model_out.data, -1)).float().mean()\n",
        "   print(float(loss))\n",
        "\n",
        "\n",
        "print(len(test_loader.dataset))\n",
        "print(len(test_loader))\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_loss_2 = torch.tensor(loss_history).mean()\n",
        "test_accuracy /= len(test_loader)\n",
        "print('Average loss: {:.10f}, or {} Accuracy: {:.4f}'.format(\n",
        "       test_loss, test_loss_2, test_accuracy, len(test_loader.dataset)))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "    \n",
        "plt.title(\"Test loss\")\n",
        "plt.xlabel(\"#iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_history, 'b')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %f' % loss)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.49290674924850464\n",
            "0.5130499601364136\n",
            "0.43590953946113586\n",
            "0.45735907554626465\n",
            "0.3868239223957062\n",
            "0.46315839886665344\n",
            "0.216996431350708\n",
            "0.41609442234039307\n",
            "0.23908595740795135\n",
            "0.5195851922035217\n",
            "0.48895490169525146\n",
            "0.7692153453826904\n",
            "0.5249449014663696\n",
            "0.8136791586875916\n",
            "0.5510523915290833\n",
            "0.5701797604560852\n",
            "0.4205814599990845\n",
            "0.2849576771259308\n",
            "0.5405169129371643\n",
            "0.5470057129859924\n",
            "0.5212822556495667\n",
            "0.7743275761604309\n",
            "0.36317089200019836\n",
            "0.4212670624256134\n",
            "0.3663294315338135\n",
            "0.5551005005836487\n",
            "0.35752764344215393\n",
            "0.48447591066360474\n",
            "0.419384628534317\n",
            "0.2475580871105194\n",
            "0.39322400093078613\n",
            "0.34857290983200073\n",
            "0.39301204681396484\n",
            "0.3762456774711609\n",
            "0.6233770251274109\n",
            "0.4101601243019104\n",
            "0.5900112390518188\n",
            "0.3887355327606201\n",
            "0.4083695113658905\n",
            "0.001814792980439961\n",
            "10000\n",
            "40\n",
            "Average loss: 0.0018096002, or 0.179422989487648 Accuracy: 0.9014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAGDCAYAAAA72Cm3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7gU5f3//9dbwBaNBYkCFmyxRKNRbB+MPzVG0Rg1ltgjlmAsifFnTTSJmsSYWBKxY2+xoTFGY9coalAQQUQFQSwUAelIUc55f/+4Z7Ll7O7ZPWd358zZ5+O65prd2Sn3GQ77OnPPPfdt7i4AAJA+yyVdAAAA0DaEOAAAKUWIAwCQUoQ4AAApRYgDAJBShDgAAClFiAOomJn1MTM3s65JlwVoZIQ40AmY2cKsqdnMFme9P7oN+/uPmZ1Ui7ICqB7+igY6AXdfJX5tZh9JOsndn0uuRADqgStxoBMzs+XM7Hwzm2hms8zsQTNbM/psRTO7J1o+18yGm9naZvZHSd+VdG10JX9tGcfpZWaPmdlsM5tgZj/N+mxHMxthZvPNbLqZXVXq+LU6F0BnxJU40Ln9XNJBkv4/STMlDZJ0naQjJR0naTVJ60laKmlbSYvd/QIz6yfpHne/pczj3C/pHUm9JG0u6Vkzm+juL0i6WtLV7n63ma0iaatom4LHb+fPCzQUrsSBzu1nki5w98nuvlTSRZIOjRqkfSWpu6RN3L3J3d909/mVHsDM1pPUT9J57r7E3UdJukXST6JVvpK0iZmt5e4L3X1Y1vJ2Hx9oZIQ40LltIOkfUXX1XEnvSWqStLakuyU9Lel+M5tqZn8xs25tOEYvSbPdfUHWso8l9Y5enyjpm5Lej6rM94+WV+v4QMMixIHO7VNJ+7r76lnTiu4+xd2/cveL3X1LSf8naX9lrp4rGd5wqqQ1zWzVrGXrS5oiSe7+gbsfKekbkv4saYiZfa2V4wMoAyEOdG43SvqjmW0gSWbWw8wOjF7vYWZbm1kXSfMVqrebo+2mS9qonAO4+6eSXpP0p6ix2rcVrr7viY5zjJn1cPdmSXOjzZpbOT6AMhDiQOd2taTHJD1jZgskDZO0U/TZOpKGKAToe5JeUqjijrc71MzmmNmgMo5zpKQ+Clfl/5D0u6xH3PpLGmtmC6P9HuHui1s5PoAymHsltWYAAKCj4EocAICUIsQBAEgpQhwAgJQixAEASClCHACAlEpd3+lrrbWW9+nTJ+liAABQN2+++ebn7t4jf3nqQrxPnz4aMWJE0sUAAKBuzOzjQsupTgcAIKUIcQAAUooQBwAgpQhxAABSihAHACClCHEAAFKKEAcAIKUIcQAAUooQBwAgpQhxAABSihAHACClGjrE582THn1U+uKLpEsCAEDlGjrEX3tN+tGPpDffTLokAABUrqFDvHv3MOdKHACQRg0d4l26hPmyZcmWAwCAtmjoEO8ajaZOiAMA0ogQFyEOAEgnQlyEOAAgnQhxEeIAgHQixEWIAwDSiRCX1NSUbDkAAGgLQlxciQMA0okQFyEOAEinhg5xOnsBAKRZQ4c4V+IAgDQjxEWIAwDSiRAXIQ4ASKeGDnHuiQMA0qyhQ9wsBDkhDgBIo4YOcSlUqRPiAIA0IsQJcQBAShHiXel2FQCQTg0f4twTBwCkVcOHONXpAIC0IsQJcQBAShHihDgAIKUIcUIcAJBShDghDgBIKUKcEAcApBQhTogDAFKKECfEAQAp1fAh3qULPbYBANKp4UOcK3EAQFoR4oQ4ACClCHFCHACQUoQ4IQ4ASClCnBAHAKRUw4c4Q5ECANKqZiFuZuuZ2Ytm9q6ZjTWzMwqsY2Y2yMwmmNnbZrZdrcpTvJySe72PCgBA+3Wt4b6XSTrL3Uea2aqS3jSzZ9393ax19pW0aTTtJOmGaF43yy1HiAMA0qlmV+LuPs3dR0avF0h6T1LvvNUOlHSXB8MkrW5mPWtVpkLMpObmeh4RAIDqqMs9cTPrI+k7kl7P+6i3pE+z3k9Wy6CXmQ00sxFmNmLmzJlVLhtX4gCAdKp5iJvZKpIelvRLd5/fln24+2B37+vufXv06FHl8hHiAIB0qmmIm1k3hQC/190fKbDKFEnrZb1fN1pWN4Q4ACCtatk63STdKuk9d7+qyGqPSfpJ1Ep9Z0nz3H1arcpUCA3bAABpVcvW6f0kHStpjJmNipb9WtL6kuTuN0r6t6T9JE2QtEjS8TUsT0E0bAMApFXNQtzdX5Fkrazjkk6rVRnKQXU6ACCtGr7HNkIcAJBWhDghDgBIqYYPcRq2AQDSquFDnIZtAIC0IsSpTgcApBQhTogDAFKKECfEAQAp1fAhTsM2AEBaNXyI07ANAJBWhDjV6QCAlCLECXEAQEoR4oQ4ACClGj7EadgGAEirhg9xGrYBANKKEKc6HQCQUoQ4IQ4ASClCnBAHAKRUw4c4DdsAAGnV8CFOwzYAQFoR4lSnAwBSihAnxAEAKUWIE+IAgJRq+BCnYRsAIK0aPsRp2AYASCtCnOp0AEBKEeKEOAAgpQhxQhwAkFINH+I0bAMApFXDhzgN2wAAaUWIU50OAEgpQpwQBwCkFCFOiAMAUqrhQ3y56AwQ5ACAtGn4EDcLc0IcAJA2hDghDgBIKUKcEAcApBQhTogDAFKq4UOchm0AgLRq+BCPr8TptQ0AkDaEONXpAICUIsQJcQBASjV8iF9+eZgvXJhsOQAAqFTDh/guu4T5cg1/JgAAadPw0bXXXmFOiAMA0qbhoyu+Jw4AQNo0fIjHaNgGAEibhg9xWqcDANKKECfEAQApRYgT4gCAlCLECXEAQEoR4oQ4ACClCHFCHACQUoQ4z4kDAFKq4UM8xpU4ACBtGj7EqU4HAKRVzULczG4zsxlm9k6Rz3c3s3lmNiqaflurspRCiAMA0qprDfd9h6RrJd1VYp2h7r5/DcvQKkIcAJBWNbsSd/eXJc2u1f6rhRAHAKRV0vfEdzGz0Wb2pJl9K4kCEOIAgLSqZXV6a0ZK2sDdF5rZfpIelbRpoRXNbKCkgZK0/vrrV7UQPGIGAEirxK7E3X2+uy+MXv9bUjczW6vIuoPdva+79+3Ro0eNylOT3QIAUDOJhbiZrWMWroPNbMeoLLPqX44wJ8QBAGlTs+p0M7tP0u6S1jKzyZJ+J6mbJLn7jZIOlXSKmS2TtFjSEe71j1JCHACQVjULcXc/spXPr1V4BC1RhDgAIK2Sbp2eOEIcAJBWhDghDgBIKUKcEAcApBQhznPiAICUavgQj3ElDgBIm4YPcarTAQBpRYgT4gCAlCLECXEAQEoR4oQ4ACClCHFCHACQUoQ4IQ4ASClCnOfEAQAp1fAh3twc5lyJAwDSpuFDfNCgMH/wwWTLAQBApRo+xD/5JMynTEm2HAAAVKrhQzy+Jx5XqwMAkBaEOK3TAQAp1fAh3qNHmK+ySrLlAACgUg0f4hdfHOaHHZZsOQAAqFTDh/hKK4U5z4sDANKm4UM8xj1xAEDaNHyI07ANAJBWhDjV6ACAlGr4EI9xJQ4ASJuGD3GuxAEAadXwIR7jShwAkDYNH+I0bAMApBUhTnU6ACClGj7EY1yJAwDSpuFDnOp0AEBaEeJUpwMAUqrhQzzGlTgAIG0aPsSXLQvzBx9MthwAAFSqrBA3szPM7OsW3GpmI81s71oXrh5mzw7z229PthwAAFSq3CvxE9x9vqS9Ja0h6VhJl9WsVHW0XMPXRQAA0qrcCIubf+0n6W53H5u1LNVo2AYASKtyQ/xNM3tGIcSfNrNVJTXXrlj1Q4gDANKqa5nrnShpW0kfuvsiM1tT0vG1K1b9EOIAgLQq90p8F0nj3H2umR0j6UJJ82pXrPohxAEAaVVuiN8gaZGZbSPpLEkTJd1Vs1LVESEOAEirckN8mbu7pAMlXevu10latXbFqh9CHACQVuXeE19gZr9SeLTsu2a2nKRutStW/RDiAIC0KvdK/HBJSxWeF/9M0rqSLq9ZqeqIEAcApFVZIR4F972SVjOz/SUtcXfuiQMAkKByu139saQ3JB0m6ceSXjezQ2tZsHqZMSPpEgAA0Dbl3hO/QNIO7j5Dksysh6TnJA2pVcHqZfz4pEsAAEDblHtPfLk4wCOzKti2Q4tHMQMAIG3KDeKnzOxpMxtgZgMkPSHp37UrVv3suWfSJQAAoG3Kqk5393PM7BBJ/aJFg939H7UrVv306pV0CQAAaJty74nL3R+W9HANy5IIWqcDANKqZIib2QJJXugjSe7uX69JqeqI8cQBAGlVMsTdvVN0rVoKIQ4ASKuGjzBCHACQVg0fYSuskHQJAABom4YPcVqnAwDSquFDHACAtKpZiJvZbWY2w8zeKfK5mdkgM5tgZm+b2Xa1KgsAAJ1RLa/E75DUv8Tn+0raNJoGSrqhhmUpixd6mA4AgA6qZiHu7i9Lml1ilQMl3eXBMEmrm1nPWpWnHH/9a5JHBwCgMkneE+8t6dOs95OjZS2Y2UAzG2FmI2bOnFmzAj39dM12DQBA1aWiYZu7D3b3vu7et0ePHkkXBwCADiHJEJ8iab2s9+tGyxLDPXEAQJokGeKPSfpJ1Ep9Z0nz3H1aguVhMBQAQKqUPYpZpczsPkm7S1rLzCZL+p2kbpLk7jcqjEe+n6QJkhZJOr5WZQEAoDOqWYi7+5GtfO6STqvV8duCK3EAQJqkomEbAABoiRAHACClCPEstE4HAKQJIQ4AQEoR4lnmzUu6BAAAlI8QzzJ+fNIlAACgfIR4lmXLki4BAADlI8SzLFiQdAkAACgfIZ6HFuoAgLQgxPM89FDSJQAAoDyEeJ45c5IuAQAA5SHEAQBIKUI8D/fEAQBpQYgDAJBShDgAAClFiOc588ykSwAAQHkI8TxLliRdAgAAytM16QIAAJBWy5ZJt98eGkXPni2tuab0gx9IvXvX5/iEeAFjx0rf+lbSpQAAdHSXXir97ne5y8yk5ub6HJ/q9AK22irpEgAA0mDixJbL6vmoMiFegrt01lnSu+8mXRIAAFoixEuYPFm66iqpf/+kSwIA6IiS7iCMEC9D0v9IAAAUQogDANBGr7yS7PEJcQAA2ujjj5M9PiEOAEBKEeIAAKQUIQ4AQEoR4iUMHx7mkycnWw4AAAohxEu4/vqkSwAAQHGEuKSdd265bN486fnn618WAADKRYircI9sp51W/3IAAFAJQlxSt24tl917b/3LAQBIl6R79CTElfw/AgAAbUGIAwCQUoS4pFVXbf8+brpJ+uCD9u8HAIByEeIqrxHbdddJs2cX//xnP5N22KF6ZQIAoDWEuKQuXVpf5/TTpRNOKL3OvHnVKQ8AIB3Mkj0+IV6BWbMKL6dhHAAgCYR4BQhrAEC2pHOBEK/Aq69Kgwe3HD826X9EAEAykv7+J8QrdPLJUp8+0kcfJV0SAECjI8TbaMMNpQULki4FACBJNGxLsS++CPOkq1MAAI2JEG8HwhsAGlvSOUCIt0OvXuEfMOl/RABAY+qadAHS7uabpY03TroUAIAkmCV7IUeIt9OZZ0qLFiVdCgBAEpKuiaU6vZ3yA3zhwmTKAQBoPIR4lV1ySdIlAAA0CkI8MmVKdfZz663hHsnJJ1dnf4Xstpu08sq12z8AIB0I8cg661RnP/FwpYMHhzC/997q7Dfb0KHS4sXV3y8AIF0I8chyNToTF14Y5q+9Jv3nP7U5BgCgMdE6vcYWLZKeeELaf//wfsKE1h9J+/OfpaYmabPNpEMOqX0ZJWnq1PDcOwAgPcyTbh9fob59+/qIESNqsu969YHb2inPLkehdePPq/VPd9990lFHSS+/LH33u9XZJwA0gmK5Ue1oNbM33b1v/vKaVqebWX8zG2dmE8zs/AKfDzCzmWY2KppOqmV5OprDD5f+9a/M+0GDpE8/rX85XnklzN9+u/7HBoDOqF7XxzULcTPrIuk6SftK2lLSkWa2ZYFVH3D3baPpllqVpyN68EHpgAPC6zfflM44Q1p//WTLBABov9SHuKQdJU1w9w/d/UtJ90s6sIbHS438luVz5khjx7a+nXv7r5aXLZNOPFEaP759+wEAJK+WId5bUnbl8ORoWb5DzOxtMxtiZuvVsDwdxsor51abr7lm8efUly4NV+hz5kh/+5u0zTaZz0aPrvzYb70l3XabdPTRlW8LAChPZ7gSL8e/JPVx929LelbSnYVWMrOBZjbCzEbMnDmzrgWslfwr708+KbzevfeGe+W/+pU0cmTuZ+PGtVz/q6+k//u/8Djb4sWh85nsX6aUtWMEgFTqDCE+RVL2lfW60bL/cfdZ7r40enuLpO0L7cjdB7t7X3fv26NHj5oUtt723Tf3fbF/8KamMM8P8GI++UT673+lPfYIV/wnnSQ9+mjm8yVLwrzclvjNzdI775S3LgCgvmoZ4sMlbWpmG5rZ8pKOkPRY9gpm1jPr7QGS3qtheVJt+HDpnntyl5V6/CzbtGmZ1yecEObjx2f2V+ovxiuukLbeWnrjjcrKCwCNLPVX4u6+TNLpkp5WCOcH3X2smV1iZlGbbP3CzMaa2WhJv5A0oFblKceeeyZ37JtuKrx84MDi2xxxhHRL1J5/6NDQX/vVV5c+zsSJYT5vnnTssaGTl1Li8P744zB/7TXpgw9KbwMAja5eIV7THtvc/d+S/p237LdZr38l6Ve1LEMlnnlG6pqyPux++tNQZb7bbuH9JptUtv2yZeVVrcfr9OsX5txbB4DkJd2wrUPp0iXpErRfqXAdNKjlslIB/sUXhDUAtEWnuBJH/ZX6xTnjjPK3+fhjqU+fzPv8sJ87V1p99YqLBwANIfX3xNPqn/9MugSVmzUr87rQL87cucW3zR697fTTpV12kV5/PTfAJSm/u/q4p7nYokXSmWeGq3dJmj49LAMA1A4hnic/nNJgrbUyrydNavn5BRcU39Ys9yp72LDQGUy+yy7LfT9mTO77q68OndFccUV4v846mcFUpk8Px7izYC8AAND5cCWOqqpkhLbHHmt9HSk8w37yyaG1+rJlYVk8lzLPtsddvN7SUD3jA0DtEeINzqzlX4yffVbetiNHSoMHh2FMAQAZXImjLto6hvrcudKOO1a+3Zgx4ZiXX96246YV7QOAxkKIoy7y74m31z//menatZBzz82dS9Jzz0k77BD6fa+WSZOkDTYIjfSSdt990te+Rve1AKqPEG9wzc3Se2V2drtgQfHP4j8ExoyRzj675TEk6ZVXCm87YEBo/V5uNX45nnkm9CN/8snS7NnV229bPP54mLdl1DkAKIUQL+C555IuQf306iW9+GJ5665XYqDYv/wl8/rDDzOvH31U2n33zPvsLlvjkdviaqfWagSmTg2PsC1dKj30UOHqqpkzpQkTMle9o0dLe+1Ver8AkFaEeAHf+17SJeiY5s0rvHzEiOJX6fmPq8V9t0vSkUeG7eL+293DY2jz54duZMeNC8uuvDI8C9+7d3iO/cILpR//OAzmYpYZ1EUKVeibbipde21m2VtvVfZzuoc/FFqzeDE92gFIFiGOqnvyyczrf/2r+HqzZ0tf/3rm/eDBoWr9oIPCgC7nnx+GVT37bOnEE8M6Y8ZIn34aXt9xR5jffntmH4sXt7/8118vrbiiNGVK8XUWLAhDvf42Gglg2bLcTncKIfABVBshXkSpL3BUx/vv576PQ3DGjDB/9NFM1Xx2LcADD7T/2I8/Hq7i85+JHzIk9Fwn5d4WyBffZ7/rrjAfODB0ulOocV41Gw6WY9Ei6dJLc5/ZR7o1NUkffZR0KdAREeJF9OqVdAkaT9wFbPYV67HHlr99qav+fD/8YZgfeGDu8sMOy7w+/XTpmGMKN7iLy/jJJ9LYsaEFulQ4OOt9BX7RRaGXvrvvru9xUTu/+Y204YaZIYGBGCFewsYbJ12CxhKH+Lvvtm37G2+sXlkk6e23pXvvlXr2lO6/v/h6W22Ved0Rqszj9gmt3Vr48MNMX/fo2J5/Psyr+QQHOgdCvITXX5dGjUq6FI2jPUPB/ulP1StHIUceGarF//Of8D6/ijx+P3t2uLdf6LN6Kfd4G28s7btvbcsCoLYI8RK6d5e22Sa3RTVqp1SL8Dg8i/n1r0uHV+/eIbBeeEHac882FU9SJvSKXXEfd1x4Nr0j/PFXTq3A0KG1OfbMmdKpp0pfflmb/QMICPEybLRR0iVoDDfc0L7tS4X41KnSU0+FxweLPRdfqiFbbMmS8BjcG28U/jxulFeq17o5c6Szzmo94A46KDMSXCXi85Bk1f4554R/zwcfTK4MQCPomnQBgGp58822bTdyZAj5uLFbawYMKP5ZqQCNl625Zphvs430k5+E10OHhmfjJ08OtQZSy7Ht335bmjZN2mef0uVra/X9q6+GceTj47dH3MCvI7QRADozQhydxrRpbdtu++3bf+y2PJ/e1JR5fd11Yb7uutIee4Rq/9j8+eF5+m22Ce/jYGxuDo8d5dcUjRuXu165dt019PG+cGFl2wFoiQFQgBSKq9Pdpd//PlwVx63tly3L7YI2W/Z/+BdfzL1XvdpqLdfv31/65jdD47SxY6VBg0L4S5lug19+ubx73lOmhE50pOq0Vp88WZo+vf37qaZhw6TPP0+6FED1cSUOVFEcXv36ZZbF3b5++KH00kuZ5c8+Kx18cOGQ3m233Pf5jxY9/XTmdfYjbtmGDAlTa1cEzc3ld260cGHo0GaNNYqvk93Hfr1b5hezyy7SZpu17GCoIxg4MPwxdt55xdfp6Lcl5s8PtULf/nbSJWk8XIkDdZIfaPfdJ62+unTIIa2PJNezZ3XLUm4ojB4dyj12bHi//vqZe/rVtnhxdYejzRffZuhobr45dDGcZvvsk7ndg/oixCuUf4UEtNcjj2Sqs8tx882V7X/ZMumWW3LvwZcb4kOGhPnDD4fuXOfMyXwWD1BTLSuv3LbW+K2pZRfK48fXpwV+R6nRKGbYsKRL0LgI8QplV4cClfj976uzn4EDi39W6Mv+r3+VfvpT6dZbw/vXXgvPcWfL7vRls83C7/ns2dIf/hCWLVkSGr3FnntO2nzzzCA0lZSnlNdfz33/l7+EseHbY911277tP/5Rugp+s82kww9v+/6B9iLEyzRsWOYv7ueek/beu/AjTeU8awzUU9yg68wzw7xfv9AoLpYftOPHhwZ4a6+dWZb/THtcvd7aMK/u4dG4SmRf1Z13XuuP1MWamlofSa5SBx8sbbFFdfZ1xRXhXFdjpD0gRoiXaaedMoNjfO97oWHRdttJv/hF7npduoSrl7/9rf5lBAp54okwX7QoMxLW/PmZz4v1hpc9mMuVV+Z+tmhRmLfWz/2gQeFeaf7/k3zNzZnXu+xSet1izjwzjCRXbGz7WJ8+uU8N1Et8DufODfPm5o7fYK1Sne3nSQNCvJ2uuCJckb/6qnTZZaHhzwUXSKecknTJgCC+apakV15p+XklI8XF4qFhn38+NEY755zM8KzZhg8P82uuCa3x802fHoK+f//c5e5hNLZ8H3wQOtvp1y8zKEjsoYfCfM01S/cZEI8E9q1vFV8n39SpuX/4tEccdF26hAuCepo1K/MHWC0Q4glw91RN22+/vadF+JVmYup80667Zl7//e9hfvzx5f3en3ii+4wZ7pMmFV9n9Ojc9/PmuS9Z0nK9bD17ZpZfc03h/4eF3pf7f7hPn+KflyMu3+TJhc9TKTvuGNYZNqy8Y8U+/DBs98QTmWNusUVl+4idfLJ7v36FP4t/hqamtu07zYr9Di9YUO3jaIR7y0zkShxAxbKv6K+9Nsy//DJTdV/KrbeGq+ANNyy+Tv647KutFnqtKyX73v5yZX6zffZZ2C67h7xiPvoo9Jv/6KPl7Ttfe/q0b8s2Uqa24vrrM8tae5yxmJtuCjWOpbS1nGg7QrwOzjhD2mCDpEsB1MZrr2Ve779/edvkt47PV6jxV2sDxmSHuJl0++0twzl/v//9b5hfc03pfccGDJB+9KPin8+bF+61m4V+AIppawO8YcNy2w+0ZtCgMC/nj6tqIMTrjxCvg7/9LfwVT8t1dGb33lu9fX3/++Wtt+22mSvL7OfBTz1VOuGElvecDzgg930cOkuWSIceGq7MH3kkhGy5A+JkW331zL32Uo/fnXNO5fuWpF/+UrrkktLD9mbL7hugkKFDa9vBTq08+qh0992tr/f++5mGhLXSo0dt99+qQnXsHXlK4z3xQsuYmJiqM33/+23/v/Xww4WX9+tXerti/8eLrefu3rt3WLbttu5HHll6XXf3555zHzDAfbvtWq67ww7lfQdtvnnu/rNf//Sn4fW555bex7hx4T5+sXJm7/fLL8srV3uVKkv+eptvXtuynH124d8R7ol3AiuuGFqqZ/vZz6RNNy38V3r+YzwAWvfss21vcT16dOHlrd37nTYtfFVXIq7uHzWqdFW7FFrt77VX+J4YObLl58OHh/21dpVZrOp98eJMz3/ZTy/EnnxSmjgxvN5ss9wOc2bPLj5QTjnnZNSoUPb4ccdSmprKr3XId9ppYV7r/vKL/cyV/n60FSFeQ4sXZ3q8it1wQ+hM47jjWq5fTs9P8T08ABnZvclV4pJL2rZdr17S0Udn3t9wQ+vbVNJ7XTwSXWsKBXDMPXzXFLLyyrnrxRYtCs/Z77eftMkm0uDBLbft3r3l43mlGu09+GD4PO50KN5nOffpDzwwXAy1RXZjvs6MEE/QMceEe1xHHx2m3r3Df4LXXpNOP73wNjvvXN8yAigs+2r61FMLr7NwYQgwM+nTT8vfd7l96e+6a+G2NkuXShdeWN4+sq/W11sv9ymAk08uvM3HH5ffZ3zcuC6+Io6DvtgfNU8+Gfr6l2rbIO/22zNDB6cZIZ6gu+8O/Vrfc0+YYrvsUvqqfP586dxzw+s+fWpaRABlKtTZzaqrVraPL7+U7rpL+vOfy9/m7rtDhz1moZr/zDPD1eull5a3/VNPSRMmhNeFfoZiDj+8ZW9/2Vfiw4aF7n3jWx35Vftm4Y+BU04JjxROmRIaFO63X+jrv5i2VFPPmBF+trgToI8/Dg0fDzmk8n11NIR4B7Xrrplf/vwetVZdNdxbl1rvdWrw4PAfopyWnADarnv39u9j98gcl4YAABH6SURBVN0L32or5aKLMhcBvXq1rcvnTTdt21Cte+wRahjiq+qhQ8MTAV99FUL+gw8y/evHLeWzbwEcd5x0442h34F11y2vpXehWorPPiv9COLaa4d/n169wvt43c8+K7z+0qX1u6fdXoR4B7bSSuGX6Y47wuhOcUMTKXSU8cgjuVfwUmjwkv2LeeKJIciPOSb858nv3hJAx7DiirVt83LxxaU/v+22tu3373/PhPjee4dn80ePlj75JHe9PfcMtw+HDg3vZ81qWbVeTnBmPxL3n/+EbXr2DN9xM2ZIb7xRftknTGhZQzB7dvi3uOyy8H633cJQvPmuuip8Ryc+Tn2hJusdeUrTI2b1Us6jL7FTT23bozj50847V2c/TExMHWM677y2bXfZZe5duuQuW2219pen2PfYiBHFt4m7ts3/Xszf7wcfZN5ff31m3yeeGB5ZjD9rbi5chlL7j6f589v+nV6IeMSs85o+vfx1//SnMO/fP9NaNN/GG2deX3ut9POft1xnt93KPyaAjq+S+/DZzj+/Zacy8QA51bJ4cebKvlQr/1ID38Ruvjn30cLbbguPu118cegSOHugHvc2FbeuzNNQyix9+/b1ESNGJF2MDie/OmrMmFC1VGiUpGnTwkhPixaF+QYbhAYo8S/vYYeFUaKGDAlVX3PmhPWkEN7du4cq/tVWa3t5Tzih7dV3ADo/98z32q67hvvmK60k/fOfodq+3G3bY9kyqWvXzD5jTU2Z5cXMn195w8ZSzOxNd++bv5wr8U7i+edzx2zeeuviwxz27CmtsIK0xhrhvs7zz4fx0e+/P3zuHvp7j+9drbFG6PBBCg3pHnlEWn758so1eXLLZfvuK3XrVt72ABAPuLN4cesBLkl//GN1jpv9GN2SJdXZZ7UR4p3EnntKV19d+XZnnhmqz81Kj/wUV6lX+tdt797hkZFsffqEav3TTw8DYbiHx2oAINaeK+lyn5FvzVFHZV7/4AeZ1/lj2SeJEMf/bLJJmPfr1/Kzo44KVVrnnVd6H5deGjqfOPjgzLInngi9QD3xRKiiv/LKcHV/zTXSWmuFdfIfoyul2B2gvfYqfx8AUIl4RLzHH5f22SfZsmQjxPE/3/lOeIztjDNafrbGGqF6ff31W362yy6Z1126hMffHn44N2xXWSVckR9ySLivVcp66xX/LD7WNttklsXDvA4YkFl2552ljwEAlXrppbaNbldLhDhybLRRedVYcaOO/feXXn5Z2n778L7ce+WlfPJJ6PP55Zdz+5Du1y/T+G7UqEwfzK+/HmoAjjgivN9++9xqsEJuvz3s/513iq/zwx9Kxx/f9p8DQOey++7lr1uvNuO0TkebTZgQ7nmvtFJo9HH55aG6va1Bfu65oQeofffNXV5JRxATJkjf+Ebo/zn/j5HBg8N40gsX5j5GF693332hNmLzzTPHmzgxc5tBknbaKfzRUMrOO4cuJ1daKTTEAdB45s3L7Ye+vYq1Tm/x4HhHn+jspfGccYb7jjtWvl12xwsnnND6erExY9xfey3z/he/yF3n5pvdR4507949s/xnPwvzPfYI69x0k/v777svXFi8M4gddmh/hxhMTEwdc5o3r/LvrNLfZ4U7e2mxoKNPhDjKFf9n+uqr0PNSMcOHu//97+XtK9s994RlL7zg/sUX7rvtFv4AyDdnjvvQoe79++f+J8/eb/50zz3uf/hDeP3oo+6HHlr9L5mjjkr+i46JqbNO9QpxqtPRafXsGR6hi0d8a49iVfqfflq6IV62RYtyx712z63yv+aazKN87qFP53fekb797dwyZFuyRJo7V1pnnUyHGOXKPv7DD3eOEZ2AjqJe1ek0bEOnNW1adQI8ttNOLZeVG+CStPLKITinT5cmTQrLLrggzC+8sOUY8sstlwlwKQyf+Omn0osvhkfzXnkldNqz9tphMIm4EWD2aFobbig99ljuflddNQxaIYXBG154ITwSOHdueT/HpEmhUSA97gEdQKHL8448UZ2OJHz5pfuyZdXf7+jRoept5MjwPq6Ka69C+7nhBvcDDii93R//mNn2vvvcJ0/OvP/gA/cLL2x5a2LAgMw63buHdgH5VYubbOL+4x+H1+efH25hFKqC7NGjetWZ3/hG8lWqTI07UZ1eBNXp6MyuvTYMg3jSSe3bj1no277cq+v8baXQDe/hh4cr9alTw1CPxYwfH7rY3XPP0BlG/CztrFmZfvebmqQvvshUMU6blhmy8uSTw7I//CE8OXDkkS2P8dVXoUOfl17KLPvGN8IYAbFhw0KNxXe/G26nxD/PaaeF2ovWhuPs1i13qEugrWidXmTiShxo3YwZbb8SuOGGcCXx1ltt27652f3GG90XLCh/m3Hj3Lt1C1f7778fjv/rX7t/+KH7rFnuEyaE9SZNCsNFLl7sPmRIy9b/hXz5ZSjTRRe1vFoaOTL3/ZQp7osWhav4Qo0JFyxw79o1d9mSJW27UjvzzOKfrbde8leSTO2baJ1eZCLEgdpqbg7V6ElqaipvveZm94MPdn/wwfCHSykffpj5gh0/Pvxx4J5ZNnx4y23iz5YuDU85xL73vbD83HPD+4UL3W+5JfdL/IEHwvyttwp/yX/1lft777VcPmlS2OeWW7b87OSTKwuS3/++5R8q2dP227e+j/32c19hhWSCMM1TpwhxSf0ljZM0QdL5BT5fQdID0eevS+rT2j4JcQBt9fLL7tOn5y579tkQ6oVI4Y+EfIsXhzYD+e0DmpvdH344XP3n7yf+Yv/qq/BIYmzRovAHxi9/GdpIZHv66bDd449n/kh56qmwLG5HMWpUbrhnH++NN8L7J590v/9+96lTM5/37RuOfe21mfU//zxsE7dNuOmmTFna+phjoT9GqjGdfXbyQd2pQ1xSF0kTJW0kaXlJoyVtmbfOqZJujF4fIemB1vZLiAOol1mzwlV4ey1eXJ39xAr1e9CrV2iY6B6+2TfcsLL9lepLIXu97t3dhw0L7996K/wxM29euK0webL7FluE4//855l+E+JbNG+8kRt0W22Vef3SS+EWyhNPuN91V2b5CSe433137naffRb2e/TR7hdcEF6PGJG7TbFwrWaDxw02cP/d75IN8Zo1bDOzXSRd5O77RO9/Fd2D/1PWOk9H6/zXzLpK+kxSDy9RKBq2AUBpS5eGRxS7dav/sWfPlgYNkn7zmzAgkhRi7ZNPwmBFixZJY8eGRo477xy6J157bemzz1ru6/33pc02C40T3cN2TU25AyBlGzMm9J2www7h8cnNNw+NJQ84QNp669x1584N+7rqqtzxx6dMkb78MjxG+cwz0j33hK6am5tDY9E+fULjyX32kZ56KmxTqA+HejVsq2WIHyqpv7ufFL0/VtJO7n561jrvROtMjt5PjNb5PG9fAyUNlKT1119/+48//rgmZQYA1FdTU5jHgV9NU6eGpxTaMzZ5Oa68Ujr77PAzNDVJW2whDR+e27lTe6W6sxd3H+zufd29b48ePZIuDgCgSrp0qU2AS1KvXrUPcEk666xQU7BsWZi/+251A7yUWob4FEnZ/VmtGy0ruE5Unb6apFk1LBMAAJ1GLUN8uKRNzWxDM1teoeFaXgeQekzScdHrQyW9UOp+OAAAyOhaqx27+zIzO13S0wot1W9z97FmdolCK7vHJN0q6W4zmyBptkLQAwCAMtQsxCXJ3f8t6d95y36b9XqJpMNqWQYAADqrVDRsAwAALRHiAACkFCEOAEBKEeIAAKQUIQ4AQEoR4gAApBQhDgBAShHiAACkFCEOAEBK1Wwo0loxs5mSqjkW6VqSPm91LVSK81obnNfq45zWBue1ujZw9xbDeKYuxKvNzEYUGqMV7cN5rQ3Oa/VxTmuD81ofVKcDAJBShDgAAClFiEuDky5AJ8V5rQ3Oa/VxTmuD81oHDX9PHACAtOJKHACAlGroEDez/mY2zswmmNn5SZenozOzj8xsjJmNMrMR0bI1zexZM/sgmq8RLTczGxSd27fNbLus/RwXrf+BmR2X1M+TFDO7zcxmmNk7Wcuqdh7NbPvo32lCtK3V9ydMRpHzepGZTYl+Z0eZ2X5Zn/0qOkfjzGyfrOUFvxfMbEMzez1a/oCZLV+/ny4ZZraemb1oZu+a2VgzOyNazu9rR+HuDTlJ6iJpoqSNJC0vabSkLZMuV0eeJH0kaa28ZX+RdH70+nxJf45e7yfpSUkmaWdJr0fL15T0YTRfI3q9RtI/W53P426StpP0Ti3Oo6Q3onUt2nbfpH/mBM/rRZLOLrDultH/+RUkbRh9F3Qp9b0g6UFJR0Svb5R0StI/cx3OaU9J20WvV5U0Pjp3/L52kKmRr8R3lDTB3T909y8l3S/pwITLlEYHSrozen2npIOylt/lwTBJq5tZT0n7SHrW3We7+xxJz0rqX+9CJ8ndX5Y0O29xVc5j9NnX3X2Yh2/Iu7L21akVOa/FHCjpfndf6u6TJE1Q+E4o+L0QXR3uKWlItH32v1Gn5e7T3H1k9HqBpPck9Ra/rx1GI4d4b0mfZr2fHC1DcS7pGTN708wGRsvWdvdp0evPJK0dvS52fjnvhVXrPPaOXucvb2SnR1W7t8XVvqr8vHaXNNfdl+Utbxhm1kfSdyS9Ln5fO4xGDnFUbld3307SvpJOM7Pdsj+M/pLmcYd24jxW1Q2SNpa0raRpkq5MtjjpZGarSHpY0i/dfX72Z/y+JquRQ3yKpPWy3q8bLUMR7j4lms+Q9A+FqsfpUZWYovmMaPVi55fzXli1zuOU6HX+8obk7tPdvcndmyXdrPA7K1V+XmcpVA13zVve6ZlZN4UAv9fdH4kW8/vaQTRyiA+XtGnU4nR5SUdIeizhMnVYZvY1M1s1fi1pb0nvKJyzuKXpcZL+Gb1+TNJPotaqO0uaF1W/PS1pbzNbI6ra3Dta1uiqch6jz+ab2c7RfdyfZO2r4cRBE/mRwu+sFM7rEWa2gpltKGlThQZWBb8XoqvNFyUdGm2f/W/UaUW/Q7dKes/dr8r6iN/XjiLplnVJTgotKccrtEa9IOnydORJobXu6GgaG58vhXuFz0v6QNJzktaMlpuk66JzO0ZS36x9naDQkGiCpOOT/tkSOJf3KVTtfqVwD/DEap5HSX0VwmqipGsVderU2aci5/Xu6Ly9rRAwPbPWvyA6R+OU1SK62PdC9H/gjeh8PyRphaR/5jqc010VqsrfljQqmvbj97XjTPTYBgBASjVydToAAKlGiAMAkFKEOAAAKUWIAwCQUoQ4AAApRYgDnZCZ/cnM9jCzg8zsV9GyS8xsr+j1L81s5Soe7yAz2zLr/f+OBaB2eMQM6ITM7AVJP5B0qaQh7v5q3ucfKTzD+3kF++zi7k1FPrtD0uPuPqTQ5wBqgxAHOhEzu1xhxKh4eM2NJU1SGH1rI0mPS+ol6QqFTk4+d/c9zGxvSRcrDM05UaEzjoVR2D8g6fsKw0+uKmmgwjCdEyQdq9Av+eOS5kXTIZJ+oyjUzex70fG6KvSIdoq7L432faekH0rqJukwd3+/ZicH6ISoTgc6EXc/R6Gnsjsk7SDpbXf/trtfkrXOIElTJe0RBfhaki6UtJeHAW5GSPr/s3Y7y923c/f7JT3i7ju4+zYKw1Ke6O6vKfSGdo67b+vuE+MNzWzFqCyHu/vWCkF+Sta+P4+OeYOks6t6MoAGQIgDnc92Ct3jbq4QtK3ZWdKWkl41s1EKfWFvkPX5A1mvtzKzoWY2RtLRkr7Vyr43kzTJ3cdH7++UlD36XTygxpuS+pRRVgBZura+CoA0MLNtFa5615X0uaSVw2IbJWmXUptKetbdjyzy+RdZr++QdJC7jzazAZJ2b1+ptTSaN4nvI6BiXIkDnYS7j3L3bRUG79hS0guS9omquBfnrb5A4f62JA2T1M/MNpH+N2LdN4scZlVJ06LhKY8usr9s4yT1ifetcA/9pQp/NABFEOJAJ2JmPSTN8TB+9ubu/m6RVQdLesrMXnT3mZIGSLrPzN6W9F+FqvhCfiPpdUmvSspuhHa/pHPM7C0z2zhe6O5LJB0v6aGoCr5Z0o1t/gEB5KB1OgAAKcWVOAAAKUWIAwCQUoQ4AAApRYgDAJBShDgAAClFiAMAkFKEOAAAKUWIAwCQUv8PXNbsPdsncj0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 0.001815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFTEQ57cMvSj"
      },
      "source": [
        "### Task 3: Fix it.\n",
        "Fix the overfitted network from the previous step (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXslGb-SMvSj"
      },
      "source": [
        "class FixedNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
        "            # Your network structure comes here\n",
        "            nn.Linear(input_shape, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        out = self.model(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYNld7drMvSk"
      },
      "source": [
        "torchsummary.summary(FixedNeuralNetwork().to(device), (28*28,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Gigc8YMvSk"
      },
      "source": [
        "model = FixedNeuralNetwork().to(device)\n",
        "opt = # YOUR CODE HERE\n",
        "loss_func = # YOUR CODE HERE\n",
        "\n",
        "# Your experiments, come here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMui_uLJ7G0d"
      },
      "source": [
        "### Conclusions:\n",
        "_Write down small report with your conclusions and your ideas._"
      ]
    }
  ]
}